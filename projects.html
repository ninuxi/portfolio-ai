<!-- projects.html -->
<!DOCTYPE html>
<html lang="it">
<head>
  <meta charset="UTF-8">
  <title>Progetti | Ninuxi</title>
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <header>
    <h1>Progetti / Projects</h1>
    <nav>
      <a href="index.html">Home</a>
      <a href="chi-sono.html">Chi sono</a>
    </nav>
  </header>

  <main>
    <section>
      <h2>üéõÔ∏è AI Audio Vision Lab</h2>
      <p><strong>Descrizione:</strong> In questo progetto uso una camera Raspberry Pi per riconoscere oggetti in tempo reale e generare musica coerente attraverso modelli AI. Il sistema lavora offline su Raspberry Pi 4 usando PyTorch e modelli Magenta convertiti in TensorFlow Lite.</p>
      <p><strong>Technologie:</strong> Python, TorchVision, Magenta, TFLite, pretty_midi, Raspberry Pi</p>
      <p><strong>GitHub:</strong> <a href="https://github.com/ninuxi/ai-audio-vision-lab" target="_blank">ai-audio-vision-lab</a></p>
    </section>

    <section>
      <h2>üé§ Live Sound & Teatro</h2>
      <p>Esperienza tecnica in eventi dal vivo e spettacoli teatrali, con gestione di mixer digitali (Yamaha, Midas, Digico), PA (L-Acoustics, D&B) e microfoni in scena. Competenze approfondite su QLab, Reaper e flussi audio complessi in contesti artistici.</p>
    </section>

    <section>
      <h2>üåç Arte & Cultura Multicanale</h2>
      <p>Installazioni sonore immersive e interattive, con uso di spatial audio (L-ISA, Spat Revolution, Dolby Atmos, Facebook360). Collaborazioni con associazioni culturali e universit√† europee su progetti educativi e performativi.</p>
    </section>

    <section>
      <h2>üì° Audio Automation & AI</h2>
      <p>Sviluppo di sistemi audio reattivi tramite microcontrollori (ESP32, Arduino) e codice (C++, Python), connessi a sensori e interfacce fisiche per esperienze audio interattive. Uso di intelligenza artificiale per generazione, riconoscimento e trasformazione audio.</p>
    </section>
  </main>

  <footer>
    <p><a href="index.html">‚Üê Torna alla Home</a></p>
  </footer>
</body>
</html>
