<!DOCTYPE html>
<html lang="en" class="scroll-smooth">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI For Live | Antonio Mainenti's Portfolio</title>
    <meta name="author" content="Antonio Mainenti">
    <meta name="description" content="Portfolio of Antonio Mainenti, a Creative Technologist specializing in AI systems for interactive audio, computer vision, and cultural heritage.">
    <meta name="keywords" content="Antonio Mainenti, Audio AI, Creative Technologist, Interactive Art, TensorFlow.js, Python, PyTorch, OSC, Spatial Audio, Cultural Heritage Tech">
    <meta property="og:title" content="AI For Live | Antonio Mainenti's Portfolio">
    <meta property="og:description" content="Portfolio of a Creative Technologist merging AI, audio, and interactive art.">
    <meta property="og:image" content="https://aiforlive.com/aiforlive-preview.png">
    <meta property="og:url" content="https://aiforlive.com/en.html">
    <meta property="og:type" content="website">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="AI For Live | Antonio Mainenti's Portfolio">
    <meta name="twitter:description" content="Portfolio of a Creative Technologist merging AI, audio, and interactive art.">
    <meta name="twitter:image" content="https://aiforlive.com/aiforlive-preview.png">
    <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Person",
      "name": "Antonio Mainenti",
      "url": "https://aiforlive.com",
      "jobTitle": "Creative Technologist & Audio AI Engineer",
      "description": "Specialist in AI systems for interactive audio and cultural heritage. I develop solutions that merge computer vision, spatial audio, and deep learning.",
      "knowsAbout": ["AI", "Interactive Art", "Audio Engineering", "Python", "TensorFlow.js", "PyTorch", "OSC", "Spatial Audio", "Cultural Heritage Technology"],
      "sameAs": [
        "https://github.com/ninuxi",
        "https://mainenti.net"
      ]
    }
    </script>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700;900&display=swap" rel="stylesheet">
    <style>
    body { font-family: 'Inter', sans-serif; }
    .brand-gradient-text {
        background-image: linear-gradient(to right, #60a5fa, #c084fc); /* Gradiente Blu -> Viola */
        -webkit-background-clip: text;
        background-clip: text;
        color: transparent;
    }
    .gradient-text {
        background-image: linear-gradient(to right, #a78bfa, #f472b6); /* Gradiente Viola -> Rosa */
        -webkit-background-clip: text;
        background-clip: text;
        color: transparent;
    }
</style>
</head>
<body class="bg-slate-900 text-gray-300">

    <div class="container mx-auto max-w-5xl px-4 py-16">

        <header class="text-center mb-24">
            <img src="/cerchio.png" alt="AI For Live Logo" class="w-40 h-40 mx-auto mb-6 rounded-full shadow-2xl shadow-purple-900/50 border-2 border-purple-500/30">
            <h1 class="text-5xl md:text-6xl font-black brand-gradient-text leading-tight">AI For Live</h1>
            <div class="mt-8">
                <h2 class="text-2xl md:text-3xl font-bold text-white">Antonio Mainenti</h2>
                <p class="text-lg md:text-xl mt-1 gradient-text font-semibold">
                    Creative Technologist & Audio AI Engineer
                </p>
                <p class="mt-4 max-w-3xl mx-auto text-gray-400">
                    Specialist in AI systems for interactive audio and cultural heritage. I design and develop solutions that merge computer vision, spatial audio, and deep learning.
                </p>
            </div>
            <div class="mt-8 flex justify-center flex-wrap items-center gap-x-6 gap-y-4">
                <a href="https://github.com/ninuxi" target="_blank" class="bg-gray-700 hover:bg-gray-600 text-white font-semibold px-5 py-2 rounded-lg transition-colors">GitHub</a>
                <a href="https://mainenti.net" target="_blank" class="bg-gray-700 hover:bg-gray-600 text-white font-semibold px-5 py-2 rounded-lg transition-colors">Website</a>
                <a href="https://mood-adaptive-art-system.vercel.app/" target="_blank" class="bg-purple-600 hover:bg-purple-500 text-white font-semibold px-5 py-2 rounded-lg transition-colors">Live Demo: MOOD System</a>
                <a href="/it.html" class="text-gray-400 hover:text-white text-sm font-semibold">View in Italian</a> </div>
        </header>

        <main>
            <h2 class="text-4xl font-bold text-white text-center mb-12">Projects</h2>
            <div class="space-y-10 mb-16">
                
                <div class="bg-slate-800/50 p-8 rounded-2xl border border-purple-500/30 shadow-2xl shadow-purple-900/20 flex flex-col">
                    <h3 class="text-3xl font-bold text-white mb-3">MOOD: Adaptive Artistic Environment</h3>
                    <p class="mb-4 text-gray-400 flex-grow">
                        A full-stack AI system that analyzes the environment (people, movement, audio) to dynamically control artistic installations via OSC/ArtNet.
                    </p>
                    <div class="mt-auto">
                        <div class="mb-4">
                            <h4 class="font-semibold text-white text-sm mb-2">Tech Stack:</h4>
                            <div class="flex flex-wrap gap-2">
                                <span class="bg-blue-500/20 text-blue-300 text-xs font-semibold px-3 py-1 rounded-full">Next.js</span>
                                <span class="bg-sky-500/20 text-sky-300 text-xs font-semibold px-3 py-1 rounded-full">TypeScript</span>
                                <span class="bg-green-500/20 text-green-300 text-xs font-semibold px-3 py-1 rounded-full">TensorFlow.js</span>
                                <span class="bg-indigo-500/20 text-indigo-300 text-xs font-semibold px-3 py-1 rounded-full">OSC</span>
                            </div>
                        </div>
                        <div class="mb-6">
                            <h4 class="font-semibold text-white text-sm mb-2">Tags:</h4>
                            <div class="flex flex-wrap gap-2">
                                <span class="bg-gray-600/50 text-gray-300 text-xs font-medium px-3 py-1 rounded-full">Real-Time</span>
                                <span class="bg-gray-600/50 text-gray-300 text-xs font-medium px-3 py-1 rounded-full">Interactive Art</span>
                                <span class="bg-gray-600/50 text-gray-300 text-xs font-medium px-3 py-1 rounded-full">Computer Vision</span>
                                <span class="bg-gray-600/50 text-gray-300 text-xs font-medium px-3 py-1 rounded-full">Full-Stack AI</span>
                            </div>
                        </div>
                        <a href="https://github.com/ninuxi/mood-showcase" target="_blank" class="bg-white text-slate-900 font-semibold px-5 py-3 rounded-lg transition-transform hover:scale-105 inline-block">Explore the Code Showcase</a>
                        <p class="text-xs text-gray-500 mt-2">(Note: The full repository is private. This showcase illustrates key components.)</p>
                    </div>
                </div>
                
                <div class="bg-slate-800/50 p-8 rounded-2xl border border-purple-500/30 shadow-2xl shadow-purple-900/20 flex flex-col">
                    <h3 class="text-3xl font-bold text-white mb-3">Audio AI Projects</h3>
                    <p class="mb-4 text-gray-400 flex-grow">
                        A collection of libraries and models for reactive audio analysis and synthesis using deep learning, including sound event classification and texture generation.
                    </p>
                    <div class="mt-auto">
                        <div class="mb-4">
                            <h4 class="font-semibold text-white text-sm mb-2">Tech Stack:</h4>
                            <div class="flex flex-wrap gap-2">
                                <span class="bg-orange-500/20 text-orange-300 text-xs font-semibold px-3 py-1 rounded-full">Python</span>
                                <span class="bg-red-500/20 text-red-300 text-xs font-semibold px-3 py-1 rounded-full">PyTorch</span>
                                <span class="bg-yellow-500/20 text-yellow-300 text-xs font-semibold px-3 py-1 rounded-full">Librosa</span>
                                <span class="bg-teal-500/20 text-teal-300 text-xs font-semibold px-3 py-1 rounded-full">Jupyter</span>
                            </div>
                        </div>
                        <div class="mb-6">
                            <h4 class="font-semibold text-white text-sm mb-2">Tags:</h4>
                             <div class="flex flex-wrap gap-2">
                                <span class="bg-gray-600/50 text-gray-300 text-xs font-medium px-3 py-1 rounded-full">Deep Learning</span>
                                <span class="bg-gray-600/50 text-gray-300 text-xs font-medium px-3 py-1 rounded-full">Audio Analysis</span>
                                <span class="bg-gray-600/50 text-gray-300 text-xs font-medium px-3 py-1 rounded-full">Sound Synthesis</span>
                                <span class="bg-gray-600/50 text-gray-300 text-xs font-medium px-3 py-1 rounded-full">MLOps</span>
                            </div>
                        </div>
                        <div class="mb-4">
                           <a href="https://github.com/ninuxi/audio-ai-projects" target="_blank" class="bg-white text-slate-900 font-semibold px-5 py-3 rounded-lg transition-transform hover:scale-105 inline-block w-full text-center">View Projects on GitHub</a>
                        </div>
                        <div>
                           <h5 class="font-semibold text-white text-sm mb-3">Live Demos:</h5>
                           <div class="flex flex-wrap gap-3">
                                <a href="https://huggingface.co/spaces/antoniiiii/audio-visualizer-demo" target="_blank" class="bg-purple-600 hover:bg-purple-500 text-white text-xs font-semibold px-3 py-1.5 rounded-full transition-colors">Demo 1: Visualizer</a>
                                <button data-accordion-trigger="demo2" class="bg-purple-600 hover:bg-purple-500 text-white text-xs font-semibold px-3 py-1.5 rounded-full transition-colors flex items-center gap-2">Demo 2: Batch Processor <span class="arrow">▼</span></button>
                                <a href="https://huggingface.co/spaces/antoniiiii/call-analytics" target="_blank" class="bg-purple-600 hover:bg-purple-500 text-white text-xs font-semibold px-3 py-1.5 rounded-full transition-colors">Demo 3: Call Analytics</a>
                                <button data-accordion-trigger="demo4" class="bg-purple-600 hover:bg-purple-500 text-white text-xs font-semibold px-3 py-1.5 rounded-full transition-colors flex items-center gap-2">Demo 4: Lab Week <span class="arrow">▼</span></button>
                                <button data-accordion-trigger="demo5" class="bg-purple-600 hover:bg-purple-500 text-white text-xs font-semibold px-3 py-1.5 rounded-full transition-colors flex items-center gap-2">Demo 5: MAXXI Experience <span class="arrow">▼</span></button>
                                <a href="#" class="bg-purple-600/40 hover:bg-purple-500/60 text-white/70 text-xs font-semibold px-3 py-1.5 rounded-full transition-colors cursor-pointer">Demo 6 (Soon)</a>
                           </div>
                        </div>
                        <div id="demo2-content" class="hidden mt-6 bg-slate-900/50 p-6 rounded-lg border border-gray-700">
                             <h4 class="text-xl font-bold text-purple-400 mb-4">Batch Processor</h4>
                             <p class="text-sm text-gray-400 mt-1 mb-3 space-y-2">
                                <span>Ideal for preparing machine learning datasets, this Python script automates repetitive tasks like resampling, volume normalization, silence trimming, and feature extraction (e.g., MFCCs, spectrograms).</span>
                                <span>Users can define a custom processing chain via a configuration file, making the tool extremely flexible for optimizing data preparation workflows.</span>
                             </p>
                             <img src="batch-processor.gif" alt="Demo of the Batch Processor in action" class="rounded-md border border-gray-600 mt-4">
                        </div>
                        <div id="demo4-content" class="hidden mt-6 bg-slate-900/50 p-6 rounded-lg border border-gray-700">
                             <h4 class="text-xl font-bold text-purple-400 mb-4">Demo Week 4</h4>
                            <div class="grid md:grid-cols-2 gap-6">
                                <div class="bg-slate-800 p-4 rounded-lg">
                                    <h5 class="font-semibold text-white">RAI Archive Integration</h5>
                                    <p class="text-sm text-gray-400 mt-1 mb-3 space-y-2">
                                        <span>Leveraging the tool's API, the script goes beyond simple downloading to enrich content with metadata, segment audio to identify speech/music, and apply speech-to-text models for transcription.</span>
                                        <span>This makes the archive searchable and allows for the analysis of vast amounts of audio data, turning raw material into structured information.</span>
                                    </p>
                                    <img src="demo-rai.gif" alt="Terminal demo running the Rai Archive Tool" class="rounded-md border border-gray-600">
                                    <p class="text-xs font-semibold text-gray-300 mt-3 mb-1">Command:</p>
                                    <pre class="bg-gray-900 p-2 rounded-md text-cyan-400 text-xs overflow-x-auto"><code>python rai-archive-tool/rai_archive_tool.py</code></pre>
                                </div>
                                <div class="bg-slate-800 p-4 rounded-lg">
                                    <h5 class="font-semibold text-white">Example 2: [Example 2 Name]</h5>
                                    <p class="text-sm text-gray-400 mt-1">Here you can add the description for the second tool or experiment from Week 4.</p>
                                </div>
                            </div>
                        </div>
                        <div id="demo5-content" class="hidden mt-6 bg-slate-900/50 p-6 rounded-lg border border-gray-700">
                             <h4 class="text-xl font-bold text-purple-400 mb-4">Interactive Audio System for Museums</h4>
                             <div class="grid md:grid-cols-2 gap-6">
                                <div class="bg-slate-800 p-4 rounded-lg">
                                    <h5 class="font-semibold text-white">Simulated Experience</h5>
                                    <p class="text-sm text-gray-400 mt-1 mb-3">
                                       This simulation shows an AI audio system applied to exhibition spaces like the MAXXI in Rome or the Triennale in Milan. Moving beyond the concept of a passive audioguide, the system tracks visitors and dynamically adapts the soundscape (music, narration) to create an engaging and personalized experience.
                                    </p>
                                    <img src="demo-maxxi.gif" alt="Demo of the interactive system for MAXXI" class="rounded-md border border-gray-600 mt-4">
                                </div>
                                <div class="bg-slate-800 p-4 rounded-lg">
                                     <h5 class="font-semibold text-white">AI Audio Processing</h5>
                                    <p class="text-sm text-gray-400 mt-1 mb-3">
                                       This demo on Hugging Face shows how the core API powers the system. Test the AI engine that selects audio content in real-time, demonstrating the backend's robustness and responsiveness.
                                    </p>
                                    <a href="https://huggingface.co/spaces/antoniiiii/production-audio-api" target="_blank" class="bg-sky-600 hover:bg-sky-500 text-white font-semibold px-4 py-2 rounded-lg transition-colors inline-block mt-4">Test the API on Hugging Face</a>
                                </div>
                             </div>
                        </div>
                    </div>
                </div>

            </div>
            
            <h3 class="text-2xl font-bold text-white text-center mb-8">Lab & Research</h3>
            <div class="grid md:grid-cols-3 gap-6">
                </div>
        </main>

        <footer class="text-center text-gray-500 border-t border-gray-800 pt-8 mt-16">
            <p>&copy; 2025 Antonio Mainenti. Built with HTML & Tailwind CSS, deployed on GitHub Pages.</p>
        </footer>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', function () {
            const accordionTriggers = document.querySelectorAll('[data-accordion-trigger]');
            
            accordionTriggers.forEach(trigger => {
                trigger.addEventListener('click', function () {
                    const contentId = this.getAttribute('data-accordion-trigger') + '-content';
                    const content = document.getElementById(contentId);
                    const arrow = this.querySelector('.arrow');

                    if (content) {
                        content.classList.toggle('hidden');
                        if (arrow) {
                            arrow.style.transform = content.classList.contains('hidden') ? 'rotate(0deg)' : 'rotate(180deg)';
                        }
                    }
                });
            });
        });
    </script>

</body>
</html>